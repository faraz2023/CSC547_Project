{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSC2547_Proj_BaseDDPG.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyN/XTGruL9OExxKU0NXZ4PP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/faraz2023/CSC547_Project/blob/main/CSC2547_Proj_BaseDDPG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37elhUYkg0GS",
        "outputId": "2fc8b78f-1677-4c62-b5e0-ab8762ecc029"
      },
      "source": [
        "!pip install box2d-py\n",
        "!pip install gym[Box_2D]\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: box2d-py in /usr/local/lib/python3.7/dist-packages (2.3.8)\n",
            "Requirement already satisfied: gym[Box_2D] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "\u001b[33m  WARNING: gym 0.17.3 does not provide the extra 'box_2d'\u001b[0m\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.19.5)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[Box_2D]) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc34ie1PdRTj"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "import os\n",
        "import torch as T\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import gym\n",
        "import numpy as np\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27qqPyzCgl-x"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqDay6SodwQh"
      },
      "source": [
        "# Utilities "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEi3wXHndkqj"
      },
      "source": [
        "def plotLearning(scores, filename, x=None, window=5):   \n",
        "    N = len(scores)\n",
        "    running_avg = np.empty(N)\n",
        "    for t in range(N):\n",
        "\t    running_avg[t] = np.mean(scores[max(0, t-window):(t+1)])\n",
        "    if x is None:\n",
        "        x = [i for i in range(N)]\n",
        "    plt.ylabel('Score')       \n",
        "    plt.xlabel('Game')                     \n",
        "    plt.plot(x, running_avg)\n",
        "    plt.savefig(filename)\n",
        "\n",
        "def make_dir(path):\n",
        "  try: os.mkdir(path)\n",
        "  except: pass"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aImk6ki3d1y9"
      },
      "source": [
        "# DDPG Implementation in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZvTlRPCd8xc"
      },
      "source": [
        "## Class for Ornstein-Uhlenbeck Action Noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mutjwgZd1UE"
      },
      "source": [
        "class OUActionNoise(object):\n",
        "    def __init__(self, mu, sigma=0.15, theta=.2, dt=1e-2, x0=None):\n",
        "        self.theta = theta\n",
        "        self.mu = mu\n",
        "        self.sigma = sigma\n",
        "        self.dt = dt\n",
        "        self.x0 = x0\n",
        "        self.reset()\n",
        "\n",
        "    def __call__(self):\n",
        "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + \\\n",
        "            self.sigma * np.sqrt(self.dt) * np.random.normal(size=self.mu.shape)\n",
        "        self.x_prev = x\n",
        "        return x\n",
        "\n",
        "    def reset(self):\n",
        "        self.x_prev = self.x0 if self.x0 is not None else np.zeros_like(self.mu)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return 'OrnsteinUhlenbeckActionNoise(mu={}, sigma={})'.format(\n",
        "                                                            self.mu, self.sigma)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOzUWffTeF-7"
      },
      "source": [
        "## Class for Reply Buffer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Hu8f7DIdyDa"
      },
      "source": [
        "class ReplayBuffer(object):\n",
        "    def __init__(self, max_size, input_shape, n_actions):\n",
        "        self.mem_size = max_size\n",
        "        self.mem_cntr = 0\n",
        "        self.state_memory = np.zeros((self.mem_size, *input_shape))\n",
        "        self.new_state_memory = np.zeros((self.mem_size, *input_shape))\n",
        "        self.action_memory = np.zeros((self.mem_size, n_actions))\n",
        "        self.reward_memory = np.zeros(self.mem_size)\n",
        "        self.terminal_memory = np.zeros(self.mem_size, dtype=np.float32)\n",
        "\n",
        "    def store_transition(self, state, action, reward, state_, done):\n",
        "        index = self.mem_cntr % self.mem_size\n",
        "        self.state_memory[index] = state\n",
        "        self.new_state_memory[index] = state_\n",
        "        self.action_memory[index] = action\n",
        "        self.reward_memory[index] = reward\n",
        "        self.terminal_memory[index] = 1 - done\n",
        "        self.mem_cntr += 1\n",
        "\n",
        "    def sample_buffer(self, batch_size):\n",
        "        max_mem = min(self.mem_cntr, self.mem_size)\n",
        "\n",
        "        batch = np.random.choice(max_mem, batch_size)\n",
        "\n",
        "        states = self.state_memory[batch]\n",
        "        actions = self.action_memory[batch]\n",
        "        rewards = self.reward_memory[batch]\n",
        "        states_ = self.new_state_memory[batch]\n",
        "        terminal = self.terminal_memory[batch]\n",
        "\n",
        "        return states, actions, rewards, states_, terminal"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGjLWx8deimW"
      },
      "source": [
        "## Critic Network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncyzMuaieL7L"
      },
      "source": [
        "class CriticNetwork(nn.Module):\n",
        "    def __init__(self, beta, input_dims, fc1_dims, fc2_dims, n_actions, name,\n",
        "                 chkpt_dir='tmp/ddpg'):\n",
        "        super(CriticNetwork, self).__init__()\n",
        "        self.input_dims = input_dims\n",
        "        self.fc1_dims = fc1_dims\n",
        "        self.fc2_dims = fc2_dims\n",
        "        self.n_actions = n_actions\n",
        "        self.checkpoint_file = os.path.join(chkpt_dir,name+'_ddpg')\n",
        "        self.fc1 = nn.Linear(*self.input_dims, self.fc1_dims)\n",
        "        f1 = 1./np.sqrt(self.fc1.weight.data.size()[0])\n",
        "        T.nn.init.uniform_(self.fc1.weight.data, -f1, f1)\n",
        "        T.nn.init.uniform_(self.fc1.bias.data, -f1, f1)\n",
        "        #self.fc1.weight.data.uniform_(-f1, f1)\n",
        "        #self.fc1.bias.data.uniform_(-f1, f1)\n",
        "        self.bn1 = nn.LayerNorm(self.fc1_dims)\n",
        "\n",
        "        self.fc2 = nn.Linear(self.fc1_dims, self.fc2_dims)\n",
        "        f2 = 1./np.sqrt(self.fc2.weight.data.size()[0])\n",
        "        #f2 = 0.002\n",
        "        T.nn.init.uniform_(self.fc2.weight.data, -f2, f2)\n",
        "        T.nn.init.uniform_(self.fc2.bias.data, -f2, f2)\n",
        "        #self.fc2.weight.data.uniform_(-f2, f2)\n",
        "        #self.fc2.bias.data.uniform_(-f2, f2)\n",
        "        self.bn2 = nn.LayerNorm(self.fc2_dims)\n",
        "\n",
        "        self.action_value = nn.Linear(self.n_actions, self.fc2_dims)\n",
        "        f3 = 0.003\n",
        "        self.q = nn.Linear(self.fc2_dims, 1)\n",
        "        T.nn.init.uniform_(self.q.weight.data, -f3, f3)\n",
        "        T.nn.init.uniform_(self.q.bias.data, -f3, f3)\n",
        "        #self.q.weight.data.uniform_(-f3, f3)\n",
        "        #self.q.bias.data.uniform_(-f3, f3)\n",
        "\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=beta)\n",
        "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cuda:1')\n",
        "\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, state, action):\n",
        "        state_value = self.fc1(state)\n",
        "        state_value = self.bn1(state_value)\n",
        "        state_value = F.relu(state_value)\n",
        "        state_value = self.fc2(state_value)\n",
        "        state_value = self.bn2(state_value)\n",
        "\n",
        "        action_value = F.relu(self.action_value(action))\n",
        "        state_action_value = F.relu(T.add(state_value, action_value))\n",
        "        state_action_value = self.q(state_action_value)\n",
        "\n",
        "        return state_action_value\n",
        "\n",
        "    def save_checkpoint(self):\n",
        "        print('... saving checkpoint ...')\n",
        "        T.save(self.state_dict(), self.checkpoint_file)\n",
        "\n",
        "    def load_checkpoint(self):\n",
        "        print('... loading checkpoint ...')\n",
        "        self.load_state_dict(T.load(self.checkpoint_file))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L93vOoacewF3"
      },
      "source": [
        "## Actor Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Mcs48aVelRc"
      },
      "source": [
        "class ActorNetwork(nn.Module):\n",
        "    def __init__(self, alpha, input_dims, fc1_dims, fc2_dims, n_actions, name,\n",
        "                 chkpt_dir='tmp/ddpg'):\n",
        "        super(ActorNetwork, self).__init__()\n",
        "        self.input_dims = input_dims\n",
        "        self.fc1_dims = fc1_dims\n",
        "        self.fc2_dims = fc2_dims\n",
        "        self.n_actions = n_actions\n",
        "        self.checkpoint_file = os.path.join(chkpt_dir,name+'_ddpg')\n",
        "        self.fc1 = nn.Linear(*self.input_dims, self.fc1_dims)\n",
        "        f1 = 1./np.sqrt(self.fc1.weight.data.size()[0])\n",
        "        T.nn.init.uniform_(self.fc1.weight.data, -f1, f1)\n",
        "        T.nn.init.uniform_(self.fc1.bias.data, -f1, f1)\n",
        "        #self.fc1.weight.data.uniform_(-f1, f1)\n",
        "        #self.fc1.bias.data.uniform_(-f1, f1)\n",
        "        self.bn1 = nn.LayerNorm(self.fc1_dims)\n",
        "\n",
        "        self.fc2 = nn.Linear(self.fc1_dims, self.fc2_dims)\n",
        "        #f2 = 0.002\n",
        "        f2 = 1./np.sqrt(self.fc2.weight.data.size()[0])\n",
        "        T.nn.init.uniform_(self.fc2.weight.data, -f2, f2)\n",
        "        T.nn.init.uniform_(self.fc2.bias.data, -f2, f2)\n",
        "        #self.fc2.weight.data.uniform_(-f2, f2)\n",
        "        #self.fc2.bias.data.uniform_(-f2, f2)\n",
        "        self.bn2 = nn.LayerNorm(self.fc2_dims)\n",
        "\n",
        "        #f3 = 0.004\n",
        "        f3 = 0.003\n",
        "        self.mu = nn.Linear(self.fc2_dims, self.n_actions)\n",
        "        T.nn.init.uniform_(self.mu.weight.data, -f3, f3)\n",
        "        T.nn.init.uniform_(self.mu.bias.data, -f3, f3)\n",
        "        #self.mu.weight.data.uniform_(-f3, f3)\n",
        "        #self.mu.bias.data.uniform_(-f3, f3)\n",
        "\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
        "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cuda:1')\n",
        "\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, state):\n",
        "        x = self.fc1(state)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = T.tanh(self.mu(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "    def save_checkpoint(self):\n",
        "        print('... saving checkpoint ...')\n",
        "        T.save(self.state_dict(), self.checkpoint_file)\n",
        "\n",
        "    def load_checkpoint(self):\n",
        "        print('... loading checkpoint ...')\n",
        "        self.load_state_dict(T.load(self.checkpoint_file))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6Ad4iEafD_U"
      },
      "source": [
        "## Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiFW6XSFexfZ"
      },
      "source": [
        "class Agent(object):\n",
        "    def __init__(self, alpha, beta, input_dims, tau, env, gamma=0.99,\n",
        "                 n_actions=2, max_size=1000000, layer1_size=400,\n",
        "                 layer2_size=300, batch_size=64, chkpt_dir='exp'):\n",
        "        self.gamma = gamma\n",
        "        self.tau = tau\n",
        "        self.memory = ReplayBuffer(max_size, input_dims, n_actions)\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.actor = ActorNetwork(alpha, input_dims, layer1_size,\n",
        "                                  layer2_size, n_actions=n_actions,\n",
        "                                  name='Actor', chkpt_dir=chkpt_dir)\n",
        "        self.critic = CriticNetwork(beta, input_dims, layer1_size,\n",
        "                                    layer2_size, n_actions=n_actions,\n",
        "                                    name='Critic', chkpt_dir=chkpt_dir)\n",
        "\n",
        "        self.target_actor = ActorNetwork(alpha, input_dims, layer1_size,\n",
        "                                         layer2_size, n_actions=n_actions,\n",
        "                                         name='TargetActor', chkpt_dir=chkpt_dir)\n",
        "        self.target_critic = CriticNetwork(beta, input_dims, layer1_size,\n",
        "                                           layer2_size, n_actions=n_actions,\n",
        "                                           name='TargetCritic', chkpt_dir=chkpt_dir)\n",
        "\n",
        "        self.noise = OUActionNoise(mu=np.zeros(n_actions))\n",
        "\n",
        "        self.update_network_parameters(tau=1)\n",
        "\n",
        "    def choose_action(self, observation):\n",
        "        self.actor.eval()\n",
        "        observation = T.tensor(observation, dtype=T.float).to(self.actor.device)\n",
        "        mu = self.actor.forward(observation).to(self.actor.device)\n",
        "        mu_prime = mu + T.tensor(self.noise(),\n",
        "                                 dtype=T.float).to(self.actor.device)\n",
        "        self.actor.train()\n",
        "        return mu_prime.cpu().detach().numpy()\n",
        "\n",
        "\n",
        "    def remember(self, state, action, reward, new_state, done):\n",
        "        self.memory.store_transition(state, action, reward, new_state, done)\n",
        "\n",
        "    def learn(self):\n",
        "        if self.memory.mem_cntr < self.batch_size:\n",
        "            return\n",
        "        state, action, reward, new_state, done = \\\n",
        "                                      self.memory.sample_buffer(self.batch_size)\n",
        "\n",
        "        reward = T.tensor(reward, dtype=T.float).to(self.critic.device)\n",
        "        done = T.tensor(done).to(self.critic.device)\n",
        "        new_state = T.tensor(new_state, dtype=T.float).to(self.critic.device)\n",
        "        action = T.tensor(action, dtype=T.float).to(self.critic.device)\n",
        "        state = T.tensor(state, dtype=T.float).to(self.critic.device)\n",
        "\n",
        "        self.target_actor.eval()\n",
        "        self.target_critic.eval()\n",
        "        self.critic.eval()\n",
        "        target_actions = self.target_actor.forward(new_state)\n",
        "        critic_value_ = self.target_critic.forward(new_state, target_actions)\n",
        "        critic_value = self.critic.forward(state, action)\n",
        "\n",
        "        target = []\n",
        "        for j in range(self.batch_size):\n",
        "            target.append(reward[j] + self.gamma*critic_value_[j]*done[j])\n",
        "        target = T.tensor(target).to(self.critic.device)\n",
        "        target = target.view(self.batch_size, 1)\n",
        "\n",
        "        self.critic.train()\n",
        "        self.critic.optimizer.zero_grad()\n",
        "        critic_loss = F.mse_loss(target, critic_value)\n",
        "        critic_loss.backward()\n",
        "        self.critic.optimizer.step()\n",
        "\n",
        "        self.critic.eval()\n",
        "        self.actor.optimizer.zero_grad()\n",
        "        mu = self.actor.forward(state)\n",
        "        self.actor.train()\n",
        "        actor_loss = -self.critic.forward(state, mu)\n",
        "        actor_loss = T.mean(actor_loss)\n",
        "        actor_loss.backward()\n",
        "        self.actor.optimizer.step()\n",
        "\n",
        "        self.update_network_parameters()\n",
        "\n",
        "    def update_network_parameters(self, tau=None):\n",
        "        if tau is None:\n",
        "            tau = self.tau\n",
        "\n",
        "        actor_params = self.actor.named_parameters()\n",
        "        critic_params = self.critic.named_parameters()\n",
        "        target_actor_params = self.target_actor.named_parameters()\n",
        "        target_critic_params = self.target_critic.named_parameters()\n",
        "\n",
        "        critic_state_dict = dict(critic_params)\n",
        "        actor_state_dict = dict(actor_params)\n",
        "        target_critic_dict = dict(target_critic_params)\n",
        "        target_actor_dict = dict(target_actor_params)\n",
        "\n",
        "        for name in critic_state_dict:\n",
        "            critic_state_dict[name] = tau*critic_state_dict[name].clone() + \\\n",
        "                                      (1-tau)*target_critic_dict[name].clone()\n",
        "\n",
        "        self.target_critic.load_state_dict(critic_state_dict)\n",
        "\n",
        "        for name in actor_state_dict:\n",
        "            actor_state_dict[name] = tau*actor_state_dict[name].clone() + \\\n",
        "                                      (1-tau)*target_actor_dict[name].clone()\n",
        "        self.target_actor.load_state_dict(actor_state_dict)\n",
        "\n",
        "\n",
        "    def save_models(self):\n",
        "        self.actor.save_checkpoint()\n",
        "        self.target_actor.save_checkpoint()\n",
        "        self.critic.save_checkpoint()\n",
        "        self.target_critic.save_checkpoint()\n",
        "\n",
        "    def load_models(self):\n",
        "        self.actor.load_checkpoint()\n",
        "        self.target_actor.load_checkpoint()\n",
        "        self.critic.load_checkpoint()\n",
        "        self.target_critic.load_checkpoint()\n",
        "\n",
        "    def check_actor_params(self):\n",
        "        current_actor_params = self.actor.named_parameters()\n",
        "        current_actor_dict = dict(current_actor_params)\n",
        "        original_actor_dict = dict(self.original_actor.named_parameters())\n",
        "        original_critic_dict = dict(self.original_critic.named_parameters())\n",
        "        current_critic_params = self.critic.named_parameters()\n",
        "        current_critic_dict = dict(current_critic_params)\n",
        "        print('Checking Actor parameters')\n",
        "\n",
        "        for param in current_actor_dict:\n",
        "            print(param, T.equal(original_actor_dict[param], current_actor_dict[param]))\n",
        "        print('Checking critic parameters')\n",
        "        for param in current_critic_dict:\n",
        "            print(param, T.equal(original_critic_dict[param], current_critic_dict[param]))\n",
        "        input()\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gtttjpd4fnI-"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcMVrHqeflvq"
      },
      "source": [
        "chkpt_dir = 'experiment_out'\n",
        "make_dir(chkpt_dir)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8nnJDwkfVHL"
      },
      "source": [
        "env = gym.make('LunarLanderContinuous-v2')\n",
        "agent = Agent(alpha=0.000025, beta=0.00025, input_dims=[8], tau=0.001, env=env,\n",
        "              batch_size=64,  layer1_size=400, layer2_size=300, n_actions=2, chkpt_dir=chkpt_dir)\n",
        "\n",
        "#agent.load_models()\n",
        "np.random.seed(0)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "ByodIV2LgWYg",
        "outputId": "7a65b042-112a-4cb9-8925-47875991b59f"
      },
      "source": [
        "score_history = []\n",
        "num_episodes = 40\n",
        "for i in range(40):\n",
        "    obs = env.reset()\n",
        "    done = False\n",
        "    score = 0\n",
        "    while not done:\n",
        "        act = agent.choose_action(obs)\n",
        "        new_state, reward, done, info = env.step(act)\n",
        "        agent.remember(obs, act, reward, new_state, int(done))\n",
        "        agent.learn()\n",
        "        score += reward\n",
        "        obs = new_state\n",
        "        #env.render()\n",
        "    score_history.append(score)\n",
        "\n",
        "    #if i % 25 == 0:\n",
        "    #    agent.save_models()\n",
        "\n",
        "    print('episode ', i, 'score %.2f' % score,\n",
        "          'trailing 100 games avg %.3f' % np.mean(score_history[-100:]))\n",
        "\n",
        "filename = 'LunarLander-alpha000025-beta00025-400-300.png'\n",
        "plotLearning(score_history, filename, window=100)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "episode  0 score -243.95 trailing 100 games avg -243.946\n",
            "episode  1 score -397.61 trailing 100 games avg -320.777\n",
            "episode  2 score -722.60 trailing 100 games avg -454.718\n",
            "episode  3 score -147.69 trailing 100 games avg -377.962\n",
            "episode  4 score -155.48 trailing 100 games avg -333.465\n",
            "episode  5 score -118.25 trailing 100 games avg -297.596\n",
            "episode  6 score -94.02 trailing 100 games avg -268.514\n",
            "episode  7 score -81.82 trailing 100 games avg -245.178\n",
            "episode  8 score -174.08 trailing 100 games avg -237.278\n",
            "episode  9 score -205.51 trailing 100 games avg -234.101\n",
            "episode  10 score -127.08 trailing 100 games avg -224.372\n",
            "episode  11 score -242.52 trailing 100 games avg -225.885\n",
            "episode  12 score -283.49 trailing 100 games avg -230.316\n",
            "episode  13 score -217.48 trailing 100 games avg -229.399\n",
            "episode  14 score -318.03 trailing 100 games avg -235.308\n",
            "episode  15 score -319.38 trailing 100 games avg -240.562\n",
            "episode  16 score -525.42 trailing 100 games avg -257.318\n",
            "episode  17 score -268.88 trailing 100 games avg -257.961\n",
            "episode  18 score -191.46 trailing 100 games avg -254.461\n",
            "episode  19 score -379.63 trailing 100 games avg -260.719\n",
            "episode  20 score -648.35 trailing 100 games avg -279.178\n",
            "episode  21 score -742.31 trailing 100 games avg -300.229\n",
            "episode  22 score -227.50 trailing 100 games avg -297.067\n",
            "episode  23 score -452.91 trailing 100 games avg -303.560\n",
            "episode  24 score -256.44 trailing 100 games avg -301.676\n",
            "episode  25 score -657.43 trailing 100 games avg -315.359\n",
            "episode  26 score -360.64 trailing 100 games avg -317.036\n",
            "episode  27 score -473.84 trailing 100 games avg -322.636\n",
            "episode  28 score -255.32 trailing 100 games avg -320.314\n",
            "episode  29 score -406.07 trailing 100 games avg -323.173\n",
            "episode  30 score -244.88 trailing 100 games avg -320.647\n",
            "episode  31 score -302.92 trailing 100 games avg -320.093\n",
            "episode  32 score -457.25 trailing 100 games avg -324.249\n",
            "episode  33 score -358.76 trailing 100 games avg -325.264\n",
            "episode  34 score -307.99 trailing 100 games avg -324.771\n",
            "episode  35 score -236.90 trailing 100 games avg -322.330\n",
            "episode  36 score -247.46 trailing 100 games avg -320.306\n",
            "episode  37 score -204.50 trailing 100 games avg -317.259\n",
            "episode  38 score -211.04 trailing 100 games avg -314.535\n",
            "episode  39 score -343.78 trailing 100 games avg -315.266\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8illl1FiL-C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}